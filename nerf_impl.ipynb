{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef8f22c2-aa8b-498b-8dfd-856b0600559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch as tr\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1dd1bb-c5d4-4b4f-a8b4-b60ebdb1f9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'tiny_nerf_data.npz' with keys: images, poses, focal"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input images, poses, and intrinsics\n",
    "data = np.load(\"tiny_nerf_data.npz\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c548dd4-2b8e-40e8-be73-3efb851ce1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to(images, height, width):\n",
    "    # images: (B, old_H, old_W, C)\n",
    "\n",
    "    # (B, C, old_H, old_W)\n",
    "    images = images.permute(0, 3, 1, 2)\n",
    "\n",
    "    transform = tv.transforms.Compose([\n",
    "        tv.transforms.Resize((height, width))\n",
    "    ])\n",
    "\n",
    "    # (B, C, new_H, new_W)\n",
    "    resized_images = torch.stack([\n",
    "        # (C, new_H, new_W)\n",
    "        transform(image)\n",
    "        for image in images\n",
    "    ])\n",
    "\n",
    "    # (B, new_H, new_W, C)\n",
    "    resized_images = resized_images.permute(0, 2, 3, 1)\n",
    "\n",
    "    return resized_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014012ae-7a46-493b-83dd-87669ed7f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([106, 32, 32, 3])\n",
      "torch.Size([106, 4, 4])\n",
      "tensor(44.4444, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "images = data['images']\n",
    "poses = data['poses']\n",
    "focal_length = data['focal']\n",
    "\n",
    "# Images\n",
    "# (B, H, W, C)\n",
    "images = torch.from_numpy(images)\n",
    "images = resize_to(images, 32, 32)\n",
    "# Camera extrinsics (poses)\n",
    "poses = torch.from_numpy(poses)\n",
    "# Focal length (intrinsics)\n",
    "focal_length = torch.from_numpy(focal_length)\n",
    "# Rescale focal length\n",
    "focal_length = focal_length * 32.0 / 100.0\n",
    "\n",
    "print(images.shape)\n",
    "print(poses.shape)\n",
    "print(focal_length)\n",
    "\n",
    "height, width = images.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a344e-2055-48d1-be1c-40f22cfe4bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85983073-391c-406b-95a4-c46bb6d58d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716f93f-e73e-4af7-a003-609e3261e47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0c5d8a-5b95-4298-b69e-556b36cb26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_get_ray_bundle(\n",
    "    height: int,\n",
    "    width: int,\n",
    "    focal_length: torch.Tensor,\n",
    "    pose: torch.Tensor\n",
    "):\n",
    "    points_x, points_y = torch.meshgrid(\n",
    "        torch.arange(width),\n",
    "        torch.arange(height),\n",
    "        indexing='xy'\n",
    "    )\n",
    "\n",
    "    points_x = (points_x - width / 2.0) / focal_length\n",
    "    # Note the -ve here, y in grid increases downwards while\n",
    "    # y in NDC increases upwards\n",
    "    points_y = -(points_y - height / 2.0) / focal_length\n",
    "    points_z = -tr.ones_like(points_x)\n",
    "\n",
    "    ray_dirs = tr.stack(\n",
    "        (\n",
    "            points_x,\n",
    "            points_y,\n",
    "            points_z,\n",
    "        ),\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    ray_dirs = F.normalize(ray_dirs, dim=-1)\n",
    "\n",
    "    transform_rot = pose[:3, :3]\n",
    "    ray_dirs = ray_dirs @ transform_rot.T\n",
    "\n",
    "    ray_origins = pose[:3, -1].expand(ray_dirs.shape)\n",
    "\n",
    "    return ray_origins, ray_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a54862-3abe-468c-966a-80f55a0ff37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_create_query_points(\n",
    "    # (H, W, 3)\n",
    "    ray_origins: torch.Tensor,\n",
    "    # (H, W, 3)\n",
    "    ray_dirs: torch.Tensor,\n",
    "    thresh_near: float,\n",
    "    thresh_far: float,\n",
    "    num_samples_per_ray: int,\n",
    "):\n",
    "    # TODO: randomize\n",
    "\n",
    "    # (N,)\n",
    "    depths = torch.linspace(thresh_near, thresh_far, num_samples_per_ray)\n",
    "\n",
    "    # (H, W, N, 3)\n",
    "    query_points = (\n",
    "        ray_origins[..., None, :]\n",
    "        + ray_dirs[..., None, :] * depths[:, None]\n",
    "    )\n",
    "\n",
    "    return query_points, depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460d2777-445d-444b-a71e-37c0ca804076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumprod_exclusive(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    cumprod = torch.cumprod(tensor, dim=-1)\n",
    "    cumprod = torch.roll(cumprod, 1, dims=-1)\n",
    "    cumprod[..., 0] = 1.\n",
    "    return cumprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae306159-ba62-431a-8901-50c8a1c1fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_render_view(\n",
    "    # (H, W, N, 4)\n",
    "    view_field: torch.Tensor,\n",
    "    # (N,) or (H, W, N)\n",
    "    depths: torch.Tensor,\n",
    "):\n",
    "    # (H, W, N, 3)\n",
    "    rgb_field = view_field[..., :3]\n",
    "    # (H, W, N)\n",
    "    sigma_field = view_field[..., 3]\n",
    "\n",
    "    rgb_field = F.sigmoid(rgb_field)\n",
    "    sigma_field = F.relu(sigma_field)\n",
    "\n",
    "    # (*, N - 1)\n",
    "    deltas = depths[..., 1:] - depths[..., :-1]\n",
    "\n",
    "    # (*, N)\n",
    "    deltas = torch.cat(\n",
    "        (\n",
    "            # (*, N - 1)\n",
    "            deltas,\n",
    "            # (*, 1)\n",
    "            torch.tensor([1e10]).expand(deltas[..., :1].shape)\n",
    "        ),\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    # (H, W, N)\n",
    "    alpha = 1. - torch.exp(-sigma_field * deltas)\n",
    "    # (H, W, N)\n",
    "    weights = alpha * cumprod_exclusive(1. - alpha + 1e-10)\n",
    "\n",
    "    # (H, W, N, 3)\n",
    "    rgb_map_points = (\n",
    "      # (H, W, N, 1)\n",
    "      weights[..., None]\n",
    "      *\n",
    "      # (H, W, N, 3)\n",
    "      rgb_field\n",
    "    )\n",
    "\n",
    "    # (H, W, 3)\n",
    "    rgb_map = rgb_map_points.sum(dim=-2)\n",
    "\n",
    "    return rgb_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cff157-9d8e-4c0b-8913-05d03abf8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(\n",
    "    # (*, D (3))\n",
    "    points,\n",
    "    L=6,\n",
    "):\n",
    "    encoding = [points]\n",
    "\n",
    "    freqs = 2.0 ** torch.linspace(0.0, L - 1, L)\n",
    "\n",
    "    for freq in freqs:\n",
    "        encoding.append(torch.sin(points * freq))\n",
    "        encoding.append(torch.cos(points * freq))\n",
    "\n",
    "    if len(encoding) == 1:\n",
    "        return encoding[0]\n",
    "    else:\n",
    "        return torch.cat(encoding, dim=-1)\n",
    "\n",
    "\n",
    "def split_points_into_chunks(\n",
    "    # (B, L)\n",
    "    points: torch.Tensor,\n",
    "    chunk_size: int\n",
    "):\n",
    "    return [\n",
    "        points[i:i + chunk_size]\n",
    "        for i in range(0, points.shape[0], chunk_size)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef62d96e-3939-41ba-9f91-22dd2d1cd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_render_pose(\n",
    "    model: torch.nn.Module,\n",
    "    height: int,\n",
    "    width: int,\n",
    "    focal_length: torch.Tensor,\n",
    "    pose: torch.Tensor,\n",
    "    thresh_near: int,\n",
    "    thresh_far: int,\n",
    "    num_samples_per_ray: int,\n",
    "    chunk_size: int,\n",
    "):\n",
    "\n",
    "    # Create rays\n",
    "    ray_origins, ray_dirs = nf_get_ray_bundle(\n",
    "        height,\n",
    "        width,\n",
    "        focal_length,\n",
    "        pose\n",
    "    )\n",
    "\n",
    "    # Create query points\n",
    "    query_points, depths = nf_create_query_points(\n",
    "        ray_origins,\n",
    "        ray_dirs,\n",
    "        thresh_near,\n",
    "        thresh_far,\n",
    "        num_samples_per_ray,\n",
    "    )\n",
    "\n",
    "    # pass query points to model\n",
    "    \"\"\"\n",
    "    model: (B, 3) -> (B, 4)\n",
    "    \"\"\"\n",
    "\n",
    "    # (H, W, N, 3)\n",
    "    # query_points\n",
    "\n",
    "    # ============ create input ============\n",
    "\n",
    "    # (H*W*N, 3)\n",
    "    flat_query_points = query_points.view(-1, 3)\n",
    "    # (H*W*N, Lx)\n",
    "    flat_query_points = positional_encoding(flat_query_points)\n",
    "\n",
    "    # (H, W, N, Ld)\n",
    "    rd_per_point = ray_dirs[..., None, :].expand(query_points.shape)\n",
    "    # (H*W*N, Ld)\n",
    "    flat_rd_per_point = rd_per_point.reshape(-1, 3)\n",
    "    flat_rd_per_point = positional_encoding(flat_rd_per_point)\n",
    "\n",
    "    flat_inputs = torch.cat([flat_query_points, flat_rd_per_point], dim=-1)\n",
    "\n",
    "    # ============ call model  ============\n",
    "\n",
    "    # convert flat_inputs to chunks\n",
    "    chunks = split_points_into_chunks(flat_inputs, chunk_size)\n",
    "    outputs = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # (Bi, 4)\n",
    "        chunk_view_field = model(chunk)\n",
    "        outputs.append(chunk_view_field)\n",
    "\n",
    "    # (H*W*N, 4)\n",
    "    flat_view_field = torch.cat(outputs, dim=0)\n",
    "\n",
    "    # create view (radiance field)\n",
    "    # (H, W, N, 4)\n",
    "    view_field = flat_view_field.view(\n",
    "        list(query_points.shape[:-1]) + [-1]\n",
    "    )\n",
    "\n",
    "    rgb_map = nf_render_view(\n",
    "        view_field,\n",
    "        depths   \n",
    "    )\n",
    "\n",
    "    return rgb_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e73d78f0-8c11-4c00-b11a-a941332c04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeryTinyNerfModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filter_size=128,\n",
    "        num_encoding_functions=6\n",
    "    ):\n",
    "\n",
    "        super(VeryTinyNerfModel, self).__init__()\n",
    "        # Input layer (default: 39 -> 128)\n",
    "        self.layer1 = torch.nn.Linear(\n",
    "            3 + 3 * 2 * num_encoding_functions + 3 + 3 * 2 * num_encoding_functions,\n",
    "            filter_size)\n",
    "        # Layer 2 (default: 128 -> 128)\n",
    "        self.layer2 = torch.nn.Linear(filter_size, filter_size)\n",
    "        # Layer 3 (default: 128 -> 4)\n",
    "        self.layer3 = torch.nn.Linear(filter_size, 4)\n",
    "        # Short hand for torch.nn.functional.relu\n",
    "        self.relu = torch.nn.functional.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62f28529-4ad9-4df1-a94a-a90567329707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VeryTinyNerfModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b83d39a0-0614-4900-a836-df6ff60d3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pose: torch.Tensor):\n",
    "    return nf_render_pose(\n",
    "        model,\n",
    "        height,\n",
    "        width,\n",
    "        focal_length,\n",
    "        pose=pose,\n",
    "        thresh_near=2,\n",
    "        thresh_far=6,\n",
    "        num_samples_per_ray=32,\n",
    "        chunk_size=8096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8386b3d3-e6c9-4307-ac94-f7e44b4df310",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c81d8cbe-9966-4094-be89-83fbb1c77cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.0017398325726389885\n",
      "100: 0.002110854024067521\n",
      "200: 0.001454812940210104\n",
      "300: 0.0009101608884520829\n",
      "400: 0.001493756310082972\n",
      "500: 0.0017555580707266927\n",
      "600: 0.0020023598335683346\n",
      "700: 0.0015028039924800396\n",
      "800: 0.0008508238825015724\n",
      "900: 0.0009786674054339528\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for i in range(1000):\n",
    "    idx = torch.randint(images.shape[0], (1,)).item()\n",
    "    target_pose = poses[idx]\n",
    "    # (H, W, 3)\n",
    "    target_image = images[idx]\n",
    "    \n",
    "    # (H, W, 3)\n",
    "    image_predicted = predict(target_pose)\n",
    "\n",
    "    loss = F.mse_loss(image_predicted, target_image)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i}: {loss.item()}\") \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "018891a9-4d3f-4bd9-9683-d19ed2ae06b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7688c3e443b0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_idx = torch.randint(images.shape[0], (1,)).item()\n",
    "# test_idx = 17\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "predicted = predict(poses[test_idx]).detach()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(predicted)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(images[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f71b5048-080a-47f5-9fb4-95fce1e91ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'model_state': model.state_dict()},'checkpoints/001.chk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19479ccf-e8ef-47ce-ba6a-09c8ab2c36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('checkpoints/001.chk')\n",
    "# model.load_state_dict(checkpoint['model_state'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
