{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8f22c2-aa8b-498b-8dfd-856b0600559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch as tr\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1dd1bb-c5d4-4b4f-a8b4-b60ebdb1f9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'tiny_nerf_data.npz' with keys: images, poses, focal"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input images, poses, and intrinsics\n",
    "data = np.load(\"tiny_nerf_data.npz\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c548dd4-2b8e-40e8-be73-3efb851ce1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to(images, height, width):\n",
    "    # images: (B, old_H, old_W, C)\n",
    "\n",
    "    # (B, C, old_H, old_W)\n",
    "    images = images.permute(0, 3, 1, 2)\n",
    "\n",
    "    transform = tv.transforms.Compose([\n",
    "        tv.transforms.Resize((height, width))\n",
    "    ])\n",
    "\n",
    "    # (B, C, new_H, new_W)\n",
    "    resized_images = torch.stack([\n",
    "        # (C, new_H, new_W)\n",
    "        transform(image)\n",
    "        for image in images\n",
    "    ])\n",
    "\n",
    "    # (B, new_H, new_W, C)\n",
    "    resized_images = resized_images.permute(0, 2, 3, 1)\n",
    "\n",
    "    return resized_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014012ae-7a46-493b-83dd-87669ed7f846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([106, 32, 32, 3])\n",
      "torch.Size([106, 4, 4])\n",
      "tensor(44.4444, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "images = data['images']\n",
    "poses = data['poses']\n",
    "focal_length = data['focal']\n",
    "\n",
    "# Images\n",
    "# (B, H, W, C)\n",
    "images = torch.from_numpy(images)\n",
    "images = resize_to(images, 32, 32)\n",
    "# Camera extrinsics (poses)\n",
    "poses = torch.from_numpy(poses)\n",
    "# Focal length (intrinsics)\n",
    "focal_length = torch.from_numpy(focal_length)\n",
    "# Rescale focal length\n",
    "focal_length = focal_length * 32.0 / 100.0\n",
    "\n",
    "print(images.shape)\n",
    "print(poses.shape)\n",
    "print(focal_length)\n",
    "\n",
    "height, width = images.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a344e-2055-48d1-be1c-40f22cfe4bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85983073-391c-406b-95a4-c46bb6d58d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716f93f-e73e-4af7-a003-609e3261e47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0c5d8a-5b95-4298-b69e-556b36cb26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_get_ray_bundle(\n",
    "    height: int,\n",
    "    width: int,\n",
    "    focal_length: torch.Tensor,\n",
    "    pose: torch.Tensor\n",
    "):\n",
    "    points_x, points_y = torch.meshgrid(\n",
    "        torch.arange(width),\n",
    "        torch.arange(height),\n",
    "        indexing='xy'\n",
    "    )\n",
    "\n",
    "    points_x = (points_x - width / 2.0) / focal_length\n",
    "    # Note the -ve here, y in grid increases downwards while\n",
    "    # y in NDC increases upwards\n",
    "    points_y = -(points_y - height / 2.0) / focal_length\n",
    "    points_z = -tr.ones_like(points_x)\n",
    "\n",
    "    ray_dirs = tr.stack(\n",
    "        (\n",
    "            points_x,\n",
    "            points_y,\n",
    "            points_z,\n",
    "        ),\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    ray_dirs = F.normalize(ray_dirs, dim=-1)\n",
    "\n",
    "    transform_rot = pose[:3, :3]\n",
    "    ray_dirs = ray_dirs @ transform_rot.T\n",
    "\n",
    "    ray_origins = pose[:3, -1].expand(ray_dirs.shape)\n",
    "\n",
    "    return ray_origins, ray_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a54862-3abe-468c-966a-80f55a0ff37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_create_query_points(\n",
    "    # (H, W, 3)\n",
    "    ray_origins: torch.Tensor,\n",
    "    # (H, W, 3)\n",
    "    ray_dirs: torch.Tensor,\n",
    "    thresh_near: float,\n",
    "    thresh_far: float,\n",
    "    num_samples_per_ray: int,\n",
    "):\n",
    "    # TODO: randomize\n",
    "\n",
    "    # (N,)\n",
    "    depths = torch.linspace(thresh_near, thresh_far, num_samples_per_ray)\n",
    "\n",
    "    # (H, W, N, 3)\n",
    "    query_points = (\n",
    "        ray_origins[..., None, :]\n",
    "        + ray_dirs[..., None, :] * depths[:, None]\n",
    "    )\n",
    "\n",
    "    return query_points, depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460d2777-445d-444b-a71e-37c0ca804076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumprod_exclusive(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    cumprod = torch.cumprod(tensor, dim=-1)\n",
    "    cumprod = torch.roll(cumprod, 1, dims=-1)\n",
    "    cumprod[..., 0] = 1.\n",
    "    return cumprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae306159-ba62-431a-8901-50c8a1c1fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_render_view(\n",
    "    # (H, W, N, 4)\n",
    "    view_field: torch.Tensor,\n",
    "    # (N,) or (H, W, N)\n",
    "    depths: torch.Tensor,\n",
    "):\n",
    "    # (H, W, N, 3)\n",
    "    rgb_field = view_field[..., :3]\n",
    "    # (H, W, N)\n",
    "    sigma_field = view_field[..., 3]\n",
    "\n",
    "    rgb_field = F.sigmoid(rgb_field)\n",
    "    sigma_field = F.relu(sigma_field)\n",
    "\n",
    "    # (*, N - 1)\n",
    "    deltas = depths[..., 1:] - depths[..., :-1]\n",
    "\n",
    "    # (*, N)\n",
    "    deltas = torch.cat(\n",
    "        (\n",
    "            # (*, N - 1)\n",
    "            deltas,\n",
    "            # (*, 1)\n",
    "            torch.tensor([1e10]).expand(deltas[..., :1].shape)\n",
    "        ),\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    # (H, W, N)\n",
    "    alpha = 1. - torch.exp(-sigma_field * deltas)\n",
    "    # (H, W, N)\n",
    "    weights = alpha * cumprod_exclusive(1. - alpha + 1e-10)\n",
    "\n",
    "    # (H, W, N, 3)\n",
    "    rgb_map_points = (\n",
    "      # (H, W, N, 1)\n",
    "      weights[..., None]\n",
    "      *\n",
    "      # (H, W, N, 3)\n",
    "      rgb_field\n",
    "    )\n",
    "\n",
    "    # (H, W, 3)\n",
    "    rgb_map = rgb_map_points.sum(dim=-2)\n",
    "\n",
    "    return rgb_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cff157-9d8e-4c0b-8913-05d03abf8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(\n",
    "    # (*, D (3))\n",
    "    points,\n",
    "    L=6,\n",
    "):\n",
    "    encoding = [points]\n",
    "\n",
    "    freqs = 2.0 ** torch.linspace(0.0, L - 1, L)\n",
    "\n",
    "    for freq in freqs:\n",
    "        encoding.append(torch.sin(points * freq))\n",
    "        encoding.append(torch.cos(points * freq))\n",
    "\n",
    "    if len(encoding) == 1:\n",
    "        return encoding[0]\n",
    "    else:\n",
    "        return torch.cat(encoding, dim=-1)\n",
    "\n",
    "\n",
    "def split_points_into_chunks(\n",
    "    # (B, L)\n",
    "    points: torch.Tensor,\n",
    "    chunk_size: int\n",
    "):\n",
    "    return [\n",
    "        points[i:i + chunk_size]\n",
    "        for i in range(0, points.shape[0], chunk_size)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef62d96e-3939-41ba-9f91-22dd2d1cd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nf_render_pose(\n",
    "    model: torch.nn.Module,\n",
    "    height: int,\n",
    "    width: int,\n",
    "    focal_length: int,\n",
    "    pose: torch.Tensor,\n",
    "    thresh_near: int,\n",
    "    thresh_far: int,\n",
    "    num_samples_per_ray: int,\n",
    "    chunk_size: int,\n",
    "):\n",
    "\n",
    "    # Create rays\n",
    "    ray_origins, ray_dirs = nf_get_ray_bundle(\n",
    "        height,\n",
    "        width,\n",
    "        focal_length,\n",
    "        pose\n",
    "    )\n",
    "\n",
    "    # Create query points\n",
    "    query_points, depths = nf_create_query_points(\n",
    "        ray_origins,\n",
    "        ray_dirs,\n",
    "        thresh_near,\n",
    "        thresh_far,\n",
    "        num_samples_per_ray,\n",
    "    )\n",
    "\n",
    "    # pass query points to model\n",
    "    \"\"\"\n",
    "    model: (B, 3) -> (B, 4)\n",
    "    \"\"\"\n",
    "\n",
    "    # (H, W, N, 3)\n",
    "    # query_points\n",
    "\n",
    "    # (H*W*N, 3)\n",
    "    flat_query_points = query_points.view(-1, 3)\n",
    "\n",
    "    # apply positional encoding\n",
    "    flat_query_points = positional_encoding(flat_query_points)\n",
    "\n",
    "    # convert flat_query_points to chunks\n",
    "    chunks = split_points_into_chunks(\n",
    "        flat_query_points, chunk_size)\n",
    "    outputs = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # (Bi, 4)\n",
    "        chunk_view_field = model(chunk)\n",
    "        outputs.append(chunk_view_field)\n",
    "\n",
    "    # (H*W*N, 4)\n",
    "    flat_view_field = torch.cat(outputs, dim=0)\n",
    "\n",
    "    # create view (radiance field)\n",
    "    # (H, W, N, 4)\n",
    "    view_field = flat_view_field.view(\n",
    "        list(query_points.shape[:-1]) + [-1]\n",
    "    )\n",
    "\n",
    "    rgb_map = nf_render_view(\n",
    "        view_field,\n",
    "        depths   \n",
    "    )\n",
    "\n",
    "    return rgb_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e73d78f0-8c11-4c00-b11a-a941332c04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeryTinyNerfModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filter_size=128,\n",
    "        num_encoding_functions=6\n",
    "    ):\n",
    "\n",
    "        super(VeryTinyNerfModel, self).__init__()\n",
    "        # Input layer (default: 39 -> 128)\n",
    "        self.layer1 = torch.nn.Linear(3 + 3 * 2 * num_encoding_functions, filter_size)\n",
    "        # Layer 2 (default: 128 -> 128)\n",
    "        self.layer2 = torch.nn.Linear(filter_size, filter_size)\n",
    "        # Layer 3 (default: 128 -> 4)\n",
    "        self.layer3 = torch.nn.Linear(filter_size, 4)\n",
    "        # Short hand for torch.nn.functional.relu\n",
    "        self.relu = torch.nn.functional.relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f28529-4ad9-4df1-a94a-a90567329707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VeryTinyNerfModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b83d39a0-0614-4900-a836-df6ff60d3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pose: torch.Tensor):\n",
    "    return nf_render_pose(\n",
    "        model,\n",
    "        height,\n",
    "        width,\n",
    "        focal_length,\n",
    "        pose=pose,\n",
    "        thresh_near=2,\n",
    "        thresh_far=6,\n",
    "        num_samples_per_ray=32,\n",
    "        chunk_size=8096,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8386b3d3-e6c9-4307-ac94-f7e44b4df310",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c81d8cbe-9966-4094-be89-83fbb1c77cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.011551345698535442\n",
      "100: 0.006947403308004141\n",
      "200: 0.004833422601222992\n",
      "300: 0.0022747572511434555\n",
      "400: 0.0023347032256424427\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for i in range(500):\n",
    "    idx = torch.randint(images.shape[0], (1,)).item()\n",
    "    target_pose = poses[idx]\n",
    "    # (H, W, 3)\n",
    "    target_image = images[idx]\n",
    "    \n",
    "    # (H, W, 3)\n",
    "    image_predicted = predict(target_pose)\n",
    "\n",
    "    loss = F.mse_loss(image_predicted, target_image)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i}: {loss.item()}\") \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "018891a9-4d3f-4bd9-9683-d19ed2ae06b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7688d19477d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_idx = torch.randint(images.shape[0], (1,)).item()\n",
    "# test_idx = 17\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "predicted = predict(poses[test_idx]).detach()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(predicted)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(images[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b5048-080a-47f5-9fb4-95fce1e91ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'model_state': model.state_dict()},'checkpoints/001.chk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19479ccf-e8ef-47ce-ba6a-09c8ab2c36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('checkpoints/001.chk')\n",
    "# model.load_state_dict(checkpoint['model_state'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
